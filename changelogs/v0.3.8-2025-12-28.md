# Release Changelog - v0.3.8 - December 28, 2025

---

## Overview

This release focuses on migrating from Vercel AI SDK v5 to v6, bringing significant improvements to streaming, provider APIs, and message handling. The migration affects the core LLM infrastructure, Ollama provider, and frontend chat components.

---

## Breaking Changes

### AI SDK v6 Migration

- **Core SDK upgraded from v5.0.8 to v6.0.3**
  - All provider packages updated to v3.x series
  - New `@ai-sdk/mcp` package added for MCP integration
  - Provider utilities upgraded to v4.x

---

## Dependencies Updated

| Package                     | Old Version | New Version |
| --------------------------- | ----------- | ----------- |
| `ai`                        | ^5.0.8      | ^6.0.3      |
| `@ai-sdk/anthropic`         | ^2.0.1      | ^3.0.1      |
| `@ai-sdk/azure`             | ^1.3.23     | ^3.0.1      |
| `@ai-sdk/google`            | ^2.0.3      | ^3.0.1      |
| `@ai-sdk/google-vertex`     | ^2.2.27     | ^4.0.1      |
| `@ai-sdk/openai`            | ^2.0.1      | ^3.0.1      |
| `@ai-sdk/openai-compatible` | ^1.0.2      | ^2.0.1      |
| `@ai-sdk/provider`          | ^2.0.0      | ^3.0.0      |
| `@ai-sdk/provider-utils`    | ^3.0.17     | ^4.0.1      |
| `@ai-sdk/react`             | ^1.2.12     | ^3.0.3      |

### New Dependencies

- `@ai-sdk/amazon-bedrock` ^3.0.72
- `@ai-sdk/mcp` ^1.0.1

---

## Refactoring

### Ollama Provider (LanguageModelV2 → LanguageModelV3)

- **Upgraded to LanguageModelV3 interface**
  - Updated `doGenerate` and `doStream` method signatures
  - Implemented custom NDJSON stream response handler for Ollama's streaming format
  - Updated type imports from `LanguageModelV2*` to `LanguageModelV3*`

- **Stream Processor Updates**
  - Updated stream part types to `LanguageModelV3StreamPart`
  - Enhanced reasoning/thinking content handling
  - Improved tool call emission with proper ID generation

- **Request Builder & Response Processor**
  - Adapted to v3 call options structure
  - Updated message conversion for v3 format
  - Enhanced tool preparation for v3 schema

### Streaming Handler Service

- **Simplified streaming architecture using `toUIMessageStreamResponse()`**
  - Replaced manual `fullStream` processing with SDK's built-in UI message stream
  - Removed custom stream chunk building (`buildToolStreamChunk` utility removed)
  - Streamlined error handling with SSE-compatible error format

- **Multi-step Tool Calling**
  - Removed reasoning model step limitation from `stopWhen` logic
  - All models now use consistent `MAX_LLM_STEPS` (30) for multi-step execution
  - Fixed tool result continuation for reasoning models

### Chat Components (Frontend)

- **Message Part Renderer**
  - Updated tool invocation state mapping for v6 stream protocol
  - Added support for new tool part states: `input-streaming`, `input-available`, `approval-requested`, `approval-responded`, `output-available`, `output-error`, `output-denied`
  - Enhanced `normalizeToolInvocationPart` for dynamic tool types

- **useChat Hook Integration**
  - Migrated to `DefaultChatTransport` for custom fetch handling
  - Updated message structure handling for v6 `UIMessage` type
  - Improved tool invocation part extraction

- **Anchored Tool Parts Hook**
  - Updated text part handling for improved clarity
  - Enhanced tool anchoring logic for v6 message structure

- **Reasoning Notification Hook**
  - Improved reasoning state detection for v6 format
  - Better handling of streaming vs completed reasoning

- **Message Persistence**
  - Updated for v6 message format compatibility

### IPC Chat Handlers

- **Stream Protocol Updates**
  - Adapted chunk encoding for v6 UI message stream format
  - Updated error response structure for SSE compatibility

### Shared Utilities

- **New `reasoning-text.ts` utility**
  - Centralized reasoning text extraction and splitting
  - Support for `<think>`, `<analysis>`, `<reasoning>` tags
  - Pattern matching for "Thinking:", "Reasoning:" prefixes

---

## Bug Fixes

- **Fixed reasoning model multi-step limitation**
  - Reasoning models no longer restricted to single step execution
  - Proper tool result continuation after reasoning blocks

- **Fixed tool state mapping**
  - Corrected state transitions for tool invocations in v6 format

---

## Technical Notes

### Stream Protocol Changes (v5 → v6)

The v6 SDK uses a different streaming protocol based on Server-Sent Events (SSE) with structured message parts:

**v5 Approach:**

```typescript
for await (const part of result.fullStream) {
  // Manual handling of text-delta, reasoning-delta, tool-call, etc.
}
```

**v6 Approach:**

```typescript
const response = result.toUIMessageStreamResponse()
// SDK handles stream formatting automatically
```

### Provider API Changes

- `LanguageModelV2` → `LanguageModelV3`
- `LanguageModelV2CallOptions` → `LanguageModelV3CallOptions`
- `LanguageModelV2StreamPart` → `LanguageModelV3StreamPart`
- New NDJSON stream handler for Ollama compatibility

### Message Part Types (v6)

New tool invocation states introduced:

- `input-streaming` - Tool arguments being streamed
- `input-available` - Tool arguments complete
- `approval-requested` - Awaiting user approval
- `approval-responded` - User responded to approval
- `output-available` - Tool result ready
- `output-error` - Tool execution failed
- `output-denied` - Tool approval denied

---

## Files Changed

### Main Process

- `src/main/services/streaming-handler-service.ts` - Streaming architecture overhaul
- `src/main/services/chat-service.ts` - Type updates
- `src/main/services/message-preparation-service.ts` - Type updates
- `src/main/services/knowledge-base-service.ts` - Type updates
- `src/main/services/vercel-mcp-adaptor-service.ts` - Type updates
- `src/main/services/reasoning-model-detector.ts` - Simplified detection logic
- `src/main/ipc/chat-handlers.ts` - Stream protocol updates
- `src/main/providers/ollama/*` - Complete v3 migration

### Renderer Process

- `src/renderer/src/features/chat/components/message/message-part-renderer.tsx` - v6 part handling
- `src/renderer/src/features/chat/hooks/useChatLogic.ts` - Transport & message updates
- `src/renderer/src/features/chat/hooks/useChatSession.ts` - Type updates
- `src/renderer/src/features/chat/hooks/use-anchored-tool-parts.tsx` - Text part handling
- `src/renderer/src/features/chat/hooks/use-chat-controller.ts` - Type updates
- `src/renderer/src/features/chat/hooks/use-message-persistence.ts` - Format updates
- `src/renderer/src/features/chat/hooks/use-reasoning-notification.ts` - State detection
- `src/renderer/src/features/chat/utils/chat-fetch.ts` - Transport updates
- `src/renderer/src/features/chat/types/message-types.ts` - New types

### Shared

- `src/shared/utils/reasoning-text.ts` - New reasoning extraction utility

### Preload

- `src/preload/index.ts` - Type updates
- `src/preload/index.d.ts` - Type declarations

---

## Statistics

- **Total Commits**: 4
- **Files Changed**: 31
- **Lines Added**: ~4,542
- **Lines Removed**: ~4,012

---

## Migration Guide

For developers extending or modifying the LLM integration:

1. **Provider implementations** must now implement `LanguageModelV3` interface
2. **Stream handling** should use `toUIMessageStreamResponse()` instead of manual `fullStream` processing
3. **Tool invocations** use new state machine with more granular states
4. **Message parts** follow the v6 UI message stream protocol

---

_Date: December 28, 2025_
